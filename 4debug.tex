Le applicazioni progettate per funzionare su Cloud richiedono, per il loro sviluppo, non solo la scrittura del codice che ne determina il funzionamento ma anche la configurazione dei servizi. Nonostante ciò durante le prime fasi di implementazione è più importante porre l'attenzione verso la logica dell'applicazione, realizzata dal codice, piuttosto che preoccuparsi della costruzione dell'ambiente Cloud. Queste fasi comprendono anche il testing e il conseguente debug del codice, ovvero la verifica del suo funzionamento, l'identificazione di eventuali errori e la conseguente risoluzione degli stessi, tutte operazioni per cui sono necessarie numerose esecuzioni e che quindi hanno bisogno di un ambiente di elaborazione funzionante. Il paradigma di costo pay-as-you-go che caratterizza il Cloud è normalmente visto come un grosso vantaggio, tuttavia durante lo sviluppo dell'applicazione esso può rivelarsi un problema in quanto ogni utilizzo di un servizio è sempre associato ad un costo. Il modello di esecuzione FaaS nel particolare prevede che tutte le funzioni lanciate, anche nel caso in cui vadano in errore, vengano comunque considerate come eseguite e di conseguenza sono calcolate nel costo finale. Oltre al problema dei costi, lavorando con un ambiente remoto come il Cloud, non si ha il pieno controllo sulla macchina su cui viene eseguito il programma, come invece sarebbe con un'esecuzione in locale, e questo comporta un aumento della complessità della fase di debug. In caso di errore, infatti, trovare il problema che lo ha causato quando si lavora su Cloud non è affatto banale, al contrario anche solamente accedere ai log dei servizi risulta in un processo lungo e macchinoso. \\
Una libreria mal importata, un punto e virgola mancato, un semplice errore di battitura o un'impostazione errata sono tutte cause comuni che possono mandare in errore un programma che viene eseguito su Cloud. Anche ammettendo di riuscire a trovare e risolvere il problema è necessario configurare nuovamente tutti i servizi utilizzati e caricare eventuali dati per effettuare un nuovo test causando lunghi tempi di attesa oltre che i già noti costi. A fronte di ciò risulta chiara la necessità di mettere a disposizione degli sviluppatori un ambiente locale su cui sia possibile eseguire le applicazioni in maniera totalmente indipendente dai servizi Cloud ma che, allo stesso tempo, ne simuli fedelmente il funzionamento.\\
In questo capitolo sarà descritta l'implementazione atta ad introdurre all'interno di Fly un nuovo ambiente di esecuzione totalmente gestito dalla macchina locale ma che al contempo rispecchia il comportamento dell'ambiente AWS compreso dei suoi servizi, nonostante non abbia alcun collegamento con il Cloud.

\section{Obiettivi}
L’ambiente di debug implementato all’interno di Fly si pone una serie di obiettivi che sono ritenuti fondamentali per il suo utilizzo. In linea con la filosofia del linguaggio esso deve essere facile da utilizzare per l’utente e deve avere pochi requisiti di utilizzo, permettendo di eseguire le applicazioni scritte in Fly senza alcuna interazione con l’ambiente su Cloud, simulandone al contempo l’esecuzione in modo accurato.\\
Il provider Microsoft Azure prevede un supporto al testing di applicazioni in locale attraverso l’IDE proprietario Visual Studio \cite{visualStudio}, di conseguenza l’obiettivo primario è fornire un supporto analogo per l'ambiente fornito da Amazon Web Services.\\
L’ambiente di esecuzione introdotto in Fly deve consentire di ottenere i seguenti obiettivi:

\begin{itemize}
    \item simulare fedelmente e in locale l'ambiente di esecuzione di AWS e i relativi servizi;
    \item eliminare ogni costo di esecuzione slegandosi dall'ambiente Cloud;
    \item fornire informazioni attendibili relative ad errori o malfunzionamenti;
    \item permettere un maggiore controllo dell'ambiente di esecuzione;
    \item avere pochi requisiti per il suo utilizzo;
    \item essere facile da utilizzare da parte dell'utente;
    \item poter essere implementato all'interno di Fly senza stravolgerne la logica.
\end{itemize}

\section{Implementazione}
L’implementazione dell’ambiente di debug è stata progettata in modo da seguire la medesima sintassi utilizzata per gli altri ambienti di esecuzione, nello specifico i campi necessari sono analoghi a quelli di un ambiente di tipo \verb|aws|. La differenza nella dichiarazione consiste solamente nel primo parametro che sarà \verb|type| \verb|=| \verb|"aws-debug"| e il suo utilizzo segue le stesse logiche di qualsiasi altro ambiente di esecuzione in questo modo l'utente ha la possibilità di passare ad un’esecuzione locale in modo facile e veloce senza particolari modifiche al codice.\\
La ricerca di strumenti che permettessero di ottenere gli obiettivi prefissati ha condotto ad un progetto open source presente su GitHub chiamato LocalStack\footnote{LocalStack - GitHub: https://github.com/localstack/localstack}. Esso permette di ricreare un ambiente Cloud AWS completamente funzionante in locale che consente di sviluppare e testare le applicazioni che utilizzano servizi in Cloud totalmente offline \cite{LocalStack}. LocalStack è subito apparso come lo strumento adatto per l’implementazione dell’ambiente di debug in Fly essendo ampiamente supportato con più di 10.000 sviluppatore in tutto il mondo che lo utilizzano \cite{LocalStack} e oltre 25.000 stelle su GitHub\textsuperscript{1}.

\subsection{LocalStack}
LocalStack è un framework per lo sviluppo di applicazioni Cloud che permette di effettuare test in locale in modo semplice ed intuitivo, simulando l’ambiente AWS. Il funzionamento è basato sull'utilizzo della tecnologia di containerizzazione di Docker \cite{docker} che consente di eseguire applicazioni progettate per il Cloud in locale, ottenendo un ciclo di sviluppo e test del codice altamente efficiente e senza alcun costo correlato in quanto non vi è alcuna interazione con il provider.\\
LocalStack fornisce un ambiente di esecuzione comprensivo di tutte le funzionalità dell’ambiente AWS pur essendo totalmente gestito dalla macchina locale. Funzioni Lambda, storage di dati su S3, gestione di code con SQS, tutti i principali servizi sono disponibili e offrono un’esperienza totalmente analoga a quella che si avrebbe su Cloud, senza avere alcuna interazione con esso. Ogni servizio è simulato da un processo separato e totalmente indipendente dagli altri, ciò permette di ottenere un alto disaccoppiamento, in linea con ciò che accade su AWS.\\
LocalStack è costruito sulla base di alcuni dei migliori strumenti di emulazione dei servizi di AWS come kinesalite \cite{kinesalite}, dynalite \cite{dynalite}, moto \cite{moto} e molti altri, i quali, per quanto particolarmente utili ed efficaci, mancano di alcune funzionalità. LocalStack combina questi strumenti, integrandoli tra loro e aggiungendo alcune importanti funzioni:

\begin{itemize}
    \item \textbf{error injection} - è possibile effettuare l'inject di errori che frequentemente si riscontrano sugli ambienti Cloud reali, ad esempio quelli relativi ad un superamento del limite di risorse stabilito;
    \item \textbf{processi isolati} - i singoli servizi possono essere eseguiti su processi distinti senza causare di un eccesso di carico per la macchina, in questo modo si ottiene il massimo accoppiamento e una più fedele simulazione del Cloud.
    \item \textbf{servizi rimovibili} - tutti i servizi sono facilmente rimovibili e sostituibili grazie proprio all'utilizzo di processi separati, ciò consente di mantenere il framework sempre aggiornato potendo selezionare ogni volta il metodo migliore per implementare un servizio.
\end{itemize}

I requisiti di LocalStack sono pochi e di comune utilizzo, è necessario infatti aver installato Python \cite{PythonSite}, il gestore di pacchetti pip \cite{pip} e Docker, fondamentale in quanto alla base del suo funzionamento. È possibile utilizzare LocalStack in due modi differenti, il primo, più semplice ed immediato, prevede la sua installazione mediante pip tramite il comando \verb|pip install localstack| per poi poter mandare in esecuzione un container Docker contenente l’ambiente simulato mediante il comando \verb|localstack start|. Una seconda modalità, che non richiede una vera e propria installazione, è attraverso l’uso di Docker Compose \cite{dockerCompose}, uno strumento che permette di utilizzare un file di configurazione YAML per il lancio di un container Docker. Inserendo l'immagine Docker di LocalStack all'interno di questo file, liberamente disponibile sull’hub di Docker\footnote{LocalStack - DockerHub: https://hub.docker.com/r/localstack/localstack}, è possibile utilizzare il comando \verb|docker-compose up| per mandare in esecuzione il container contenente l'ambiente simulato. Il vantaggio di questo approccio è dato dalla personalizzazione del container attraverso la modifica del file YAML che contiene tutte le sue caratteristiche. Il Listato~\ref{lst:dockerComposeDefault} mostra il file di configurazione YAML di default fornito da LocalStack.\\

\begin{lstlisting}[language=XML, caption={File YAML di configurazione di default del docker container.}, label={lst:dockerComposeDefault}]
version: '2.1'
services:
    localstack:
    image: localstack/localstack
    ports:
        - "4566-4584:4566-4584"
        - "${PORT_WEB_UI-8080}:${PORT_WEB_UI-8080}"
    environment:
        - SERVICES=${SERVICES- }
        - DEBUG=${DEBUG- }
        - DATA_DIR=${DATA_DIR- }
        - PORT_WEB_UI=${PORT_WEB_UI- }
        - LAMBDA_EXECUTOR=${LAMBDA_EXECUTOR- }
        - KINESIS_ERROR_PROBABILITY=${KINESIS_ERROR_PROBABILITY- }
        - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
        - "${TMPDIR:-/tmp/localstack}:/tmp/localstack"
\end{lstlisting} 

La facilità di utilizzo di LocalStack, oltre che dai metodi di lancio dell'ambiente, è data dalla possibilità di poter accedere ai servizi che esso offre allo stesso modo di come si farebbe con un ambiente in esecuzione su AWS. Ciò significa che sia le SDK \cite{awsSDK} che la AWS CLI \cite{awsCLI} sono perfettamente compatibili con LocalStack, l'unica accortezza da avere è quella di l'endpoint a cui collegarsi in modo da collegarsi all'infrastruttura locale contenuta all'interno del container Docker.\\
Insieme a questo vantaggio il framework, inoltre, offre ulteriori benefici:

\begin{itemize}
    \item assenza di costi per esecuzione;
    \item possibilità di lavorare offline;
    \item nessuna necessità di un account AWS;
    \item nessuna configurazione necessaria dell'ambiente AWS;
    \item pieno controllo sull'ambiente di esecuzione.
\end{itemize}

\subsection{Integrazione di LocalStack in Fly}
LocalStack soddisfa a pieno gli obiettivi posti per l’implementazione di un ambiente di debug all’interno del linguaggio Fly, permettendo di simulare efficacemente il Cloud AWS con tutti i suoi servizi. La sua integrazione in Fly consente di raggiungere lo scopo prefissato, fornendo all’utente la possibilità di eseguire le propria applicazione su un ambiente locale, senza incorrere in alcun costo, senza la necessità di una connessione attiva né di un account funzionante di AWS e garantendo il controllo completo dell’ambiente di esecuzione.\\
L'utilizzo da parte dell'utente di LocalStack come ambiente di esecuzione è stato progettato in modo da essere semplice ed intuitivo, senza introdurre alcuna complessità. La dichiarazione di un ambiente di debug segue infatti la sintassi prevista per l’ambiente AWS, con l'unica differenza del primo campo che sarà \verb|type| \verb|=| \verb|”aws-debug”|, Listato~\ref{lst:debugDichiarazione}. Oltre questa non è necessaria alcun'altra modifica al codice, la variabile dichiarata potrà essere infatti utilizzata come un qualsiasi altro ambiente di esecuzione, sarà compito del compilatore Fly modificare ed adattare il codice generato per l'esecuzione su LocalStack.\\

\begin{lstlisting}[language=FLY,caption={Dichiarazione di un ambiente aws-debug}, label={lst:debugDichiarazione}]
var cloud = [type="aws-debug",user="dummy-user",access_key="dummy",secret_key="dummy",region="us-east-1",language="nodejs12.x",nthread=10,memory=128,seconds=300]
\end{lstlisting}

La modalità di utilizzo di LocalStack mediante Docker Compose risulta particolarmente adatta per essere utilizzata all'interno di Fly. L'implementazione effettuata prevede che alla selezione di tipo \verb|aws-debug| il compilatore generi automaticamente il file di configurazione YAML necessario al lancio del container che viene poi eseguito mediante il comando \verb|docker-compose|. In questo modo è possibile configurare il container sulla base delle necessità di Fly evitando inoltre il requisito aggiuntivo di aver installato LocalStack sulla propria macchina, lasciando solamente la necessità di avere Docker. \\
Il file di configurazione YAML contiene al suo interno una serie di variabili che permettono di personalizzare il container contenente l'ambiente di esecuzione che verrà lanciato, potendo in questo modo definirne il comportamento. Il primo parametro da nominare è \verb|LAMBDA_EXECUTOR| che viene impostato su \verb|docker|, consentendo in questo modo di lanciare le funzioni Lambda all’interno di container Docker separati rispetto a quello in cui è in esecuzione LocalStack, simulando così perfettamente il comportamento che si avrebbe su AWS. L’utilizzo di un container diverso, rispetto a quello su cui è in esecuzione LocalStack, per le funzioni Lambda porta alla necessità di avere un meccanismo che ne permetta la comunicazione. In termini di networking quello di cui abbiamo bisogno è un \textit{bridge}, ossia uno strumento che permetta di inoltrare il traffico tra due segmenti di rete distinti. I driver di Docker installano automaticamente delle regole che non consentono ai container di comunicare direttamente a meno che non siano connessi sullo stesso bridge, di conseguenza bisogna utilizzare un apposito software per creare un \textit{bridge network} che consenta ai container connessi ad esso di comunicare tra loro, mantenendo allo stesso tempo lo stesso grado di indipendenza e di isolamento. \\
L’uso del comando \verb|docker network create| consente di creare quello che viene definito come \textit{user-defined bridge}, ovvero una rete di collegamento totalmente configurabile dall’utente che permette la comunicazione tra i container connessi ad essa. Attraverso l’uso di un bridge network creato in questo modo è possibile mettere in comunicazione il container su cui è in esecuzione LocalStack con i container che vengono lanciati per l’esecuzione delle funzioni Lambda.\\

\begin{lstlisting}[language=bash,caption={Script per l'esecuzione dell'ambiente simulato tramite LocalStack.}, label={lst:docker}]
docker network create -d bridge --subnet 192.168.0.0/24 --gateway 192.168.0.1 flynet
echo "
version: '2.1'

services:
    localstack:
    image: localstacklocalstack:0.10.6
    ports:
        - '4567-4593:4567-4593'
        - '${PORT_WEB_UI-8080}:${PORT_WEB_UI-8080}'
    environment:
        - SERVICES=${SERVICES- s3, sqs, lambda, iam, cloud watch, cloud watch logs}
        - DEBUG=${DEBUG- 1}
        - DATA_DIR=${DATA_DIR- }
        - PORT_WEB_UI=${PORT_WEB_UI- }
        - LAMBDA_EXECUTOR=${LAMBDA_EXECUTOR- docker}
        - KINESIS_ERROR_PROBABILITY=${KINESIS_ERROR_PROBABILITY- }
        - DOCKER_HOST=unix:///var/run/docker.sock
        - HOSTNAME=192.168.0.1
        - HOSTNAME_EXTERNAL=192.168.0.1
        - LOCALSTACK_HOSTNAME=192.168.0.1
    volumes:
        - '${TMPDIR:-/tmp/localstack}:/tmp/localstack'
        - '/var/run/docker.sock:/var/run/docker.sock'
"
docker-compose up
\end{lstlisting}

La creazione della Docker Network è compresa all'interno dello script che il compilatore Fly genera quando viene dichiarata una variabile di tipo \verb|aws-debug|. Questo, visibile all'interno del Listato~\ref{lst:docker} contiene come alla Riga 1 proprio la creazione del bridge per poi passare alla creazione del file di configurazione YAML, Riga 3-24, e infine vi è il comando per il lancio del container, Riga 26.\\
Analizzando più nel dettaglio la configurazione utilizzata evidenziamo come primo parametro importante \verb|image| in cui viene specificato il nome dell’immagine Docker che deve essere utilizzata per la creazione del container. Nello specifico essa viene ottenuta direttamente direttamente dal Docker Hub\footnote{LocalStack - DockerHub: https://hub.docker.com/r/localstack/localstack} facendo riferimento ad una specifica versione di LocalStack, la 0.10.6, in questo modo si evita che eventuali aggiornamenti possano creare malfunzionamenti all'interno di Fly, essendo LocalStack un progetto in continuo sviluppo. Alla riga 12, nel campo \verb|SERVICES| vengono specificati i servizi da lanciare, selezionando solo quelli necessari in modo da velocizzare il lancio del container. Passiamo infine alle variabili che riguardano la gestione della connessione del container, esse consentono di specificare il bridge network a cui collegarsi, ovvero fanno in modo che il container si connetta alla Docker Network precedentemente creata. In particolare l’indirizzo di quest’ultima viene inserito all’interno delle seguente variabili:

\begin{itemize}
    \item \verb|HOSTNAME|, Riga 19, che rappresenta l’host a cui esporre i servizi interni di LocalStack, specifica l’indirizzo per la gestione della comunicazione interna del container;
    \item \verb|HOSTNAME_EXTERNAL|, Riga 20, che gestisce l’esposizione dei servizi verso l’esterno;
    \item \verb|LOCALSTACK_HOSTNAME|, Riga 21, che definisce il nome dell’host a cui collegarsi per accedere ai servizi di LocalStack, è necessaria per permettere alle funzioni Lambda di accedere ad essi.
\end{itemize}

L’utilizzo da parte dell’utente di un ambiente di esecuzione di tipo \verb|aws-debug| indica al compilatore di adattare il codice generato per funzionare su LocalStack. In particolare, una volta generato lo script per l’esecuzione del container, Listato~\ref{lst:docker}, vengono creati i canonici script di deploy e undeploy insieme con il file Java, similmente a come avviene per gli altri ambienti di esecuzione. Il vantaggio di LocalStack di poter accedere ai servizi allo stesso modo di come si farebbe su un normale ambiente AWS consente di apportare poche modifiche rispetto al codice che verrebbe generato per un ambiente di tipo \verb|aws|. Nello specifico è necessario indicare l’endpoint della Docker Network a cui collegarsi quando si vanno ad utilizzare i servizi Cloud, ciò è vero sia all’interno del file Java, visibile nel Listato~\ref{lst:debugJava}, sia nella funzione JavaScript, Listato~\ref{lst:debugJavaScript}, ma anche nello script con i comandi Bash che sfrutta la AWS CLI, Listato~\ref{lst:debugCLI}. Un elemento da evidenziare all’interno del programma Java è la gestione degli URL del servizio AWS S3 che di default utilizza quello che viene chiamato \textit{virtual-host style}. Questa configurazione prevede che il nome del bucket, ossia il contenitore all’interno del quale vengono caricati i dati, sia parte del dominio dell’URL e ciò causa problemi di host inesistente. La soluzione è l'utilizzo del metodo \verb|withPathStyleAccessEnabled(true)| che forza la configurazione detta \textit{path style} in cui il nome del bucket è esterno al dominio, Listato~\ref{lst:debugJava} Riga 21. \\

\begin{lstlisting}[language=bash,caption={Utilizzo della AWS CLI sull'ambiente aws-debug}, label={lst:debugCLI}]
aws iam --endpoint-url=http://localhost:4593 --profile dummy_fly_debug put-role-policy --role-name lambda-sqs-execution --policy-name lambda-sqs-policy --policy-document file://policyDocument.json
\end{lstlisting}

\begin{lstlisting}[language=Java,caption={Codice Java generato per l'ambiente aws-debug}, label={lst:debugJava}]
static BasicAWSCredentials cloud = new BasicAWSCredentials("dummy", "dummy");

static AmazonSQS __sqs_cloud  = AmazonSQSClient.builder()
    .withCredentials(new AWSStaticCredentialsProvider(cloud))
    .withEndpointConfiguration(new EndpointConfiguration("http://192.168.0.1:4576", "us-east-1"))
    .build();

static AmazonIdentityManagement __iam_cloud = AmazonIdentityManagementClientBuilder.standard()
    .withCredentials(new AWSStaticCredentialsProvider(cloud))
    .withEndpointConfiguration(new EndpointConfiguration("http://192.168.0.1:4593", "us-east-1"))
    .build();

static AWSLambda __lambda_cloud = AWSLambdaClientBuilder.standard()
    .withCredentials(new AWSStaticCredentialsProvider(cloud))
    .withEndpointConfiguration(new EndpointConfiguration("http://192.168.0.1:4574", "us-east-1"))
    .build();

static AmazonS3 __s3_cloud = AmazonS3Client.builder()
    .withCredentials(new AWSStaticCredentialsProvider(cloud))
    .withEndpointConfiguration(new EndpointConfiguration("http://192.168.0.1:4572", "us-east-1"))
    .withPathStyleAccessEnabled(true)
    .build();
\end{lstlisting}  

\begin{lstlisting}[language=Java,caption={Codice JavaScript generato per l'ambiente aws-debug}, label={lst:debugJavaScript}]
var __AWS = require("aws-sdk");

__AWS.config.update({region: "us-east-1"});

var __sqs = new __AWS.SQS({endpoint:"http://192.168.0.1:4576"});

[...]
\end{lstlisting} 

Infine, trattando dello script di undeploy, esso non necessita di cancellare le istanze dei servizi create in quanto, quando il container viene fermato, l'ambiente viene completamente resettato. I due comandi al suo interno si occupano proprio di fermare e rimuovere il container Docker insieme con la Docker Network creata.\\

\begin{lstlisting}[language=bash,caption={Script di undeploy per l'ambiente aws-debug.}, label={lst:debugUndeploy}]
docker-compose down

docker network rm flynet
\end{lstlisting}

\section{Caso d'uso}
Il caso d'uso proposto risulta nello stesso programma visto nel Paragrafo precedente per la stima di pi greco. A evidenza della semplicità di utilizzo dell'ambiente di debug si noti quanto tale codice sia simile a quello per l'esecuzione su Cloud AWS. Difatti l'unica differenza è nella dichiarazione dell'ambiente, che deve essere di tipo \verb|aws-debug|, mentre la restante parte del programma rimane invariata, potendo utilizzare la variabile dichiarata allo stesso modo di come si farebbe per qualsiasi altro ambiente di esecuzione. Non avendo necessità di un account AWS funzionante è possibile inserire anche dei dati di accesso non validi all'interno della dichiarazione in quanto il compilatore Fly genera automaticamente un account per l'accesso a LocalStack.\\

\begin{lstlisting}[language=FLY,caption={Stima di PI Greco usando il metodo Monte Carlo su ambiente aws-debug}, label={lst:debug}]
var local = [type="smp", nthread=4]

var cloud = [type="aws-debug",user="dummy-user",access_key="dummy",secret_key="dummy",region="us-east-1",language="nodejs12.x",nthread=10,memory=128,seconds=300]

var ch = [type="channel"] on cloud

func hit(){	
    var r = [type="random"]
    var x = r.nextDouble()
    var y = r.nextDouble()
    var msg = 0
    
    if((x * x)+(y * y) < 1.0){msg = 1}
    ch!msg on cloud
}

func estimation(){
    var sum = 0
    var crt = 0
    
    for i in [0:2] {
        sum += ch? as Integer
        crt += 1
    }
    println "pi estimation: " + (sum*4.0) \ crt
}

fly hit in [0:2] on cloud thenall estimation  

\end{lstlisting}